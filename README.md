You're right: the code fences are broken. Use proper fenced Markdown blocks with language tags and blank lines before/after. Here’s a cleaned version you can paste over your README:``` markdown
# Overview

This project demonstrates various approaches to Information Retrieval (IR) in Python using a collection of medical-text documents. It covers these main topics:
- Building an Inverted Index from text.
- Using TF-IDF ranking to answer queries (multiple variants: raw TF, logarithmic TF, etc.).
- Comparing TF-IDF ranking with more advanced methods (ColBERT).
- Evaluating results using metrics such as Precision and Recall.

Although the project references medical texts, it is a general demonstration of IR techniques, with specific focus on:
- Preprocessing text (including tokenization, stemming, and stopword removal)
- Building, storing, and reading inverted indexes
- Computing TF-IDF scores in different ways (raw and logarithmic)
- Performing queries and ranking documents by cosine similarity
- Evaluating your indexing and search engine results versus a more advanced pretrained model (ColBERT)

# Project Structure

Below are some of the key files and their purposes (most relevant for getting started). The code is split up to demonstrate multiple ways of building and querying an IR system:

- script1.py
  - Reads documents from a folder and builds a simple inverted index.
  - Demonstrates basic text preprocessing.
  - Saves the inverted index to a file (inverted_index.py).

- tfidfscript.py
  - Extends the baseline approach by computing TF-IDF scores with an optional logarithmic term frequency.
  - Prints and optionally saves the TF-IDF matrix.

- rawscript2.py / rawscript2detailed.py
  - Variations that read an inverted index file and apply TF-IDF.
  - Allow for comparing raw TF vs. logarithmic TF.
  - Demonstrate how to query the documents, compute scores, and write the top results to an output file.

- logscript2.py
  - Variation combining logarithmic TF with IDF.
  - Provides an example query and writes top results to a file.

- main.py
  - Pulls everything together:
    - Reads an inverted index.
    - Calculates TF-IDF with simple logarithmic normalization.
    - Queries for “Is CF mucus abnormal” and records top results.

- script2skcheck.py
  - Uses scikit-learn’s TfidfVectorizer for cross-checking TF-IDF results.
  - Compares manual IR with an out-of-the-box library approach.

- script3.py / script32.py
  - Index and search with ColBERT (advanced IR).
  - script3.py creates an index; script32.py performs the searching.

- script4.py
  - Reads query results (TF-IDF and ColBERT) and computes Precision@N / Recall@N.

- csvtotsv.py / docstocsv.py
  - Converts raw .docs files into .csv or .tsv for pipelines that need them.

- inverted_index.py
  - Generated by script1.py. Holds the terms and document IDs in a rudimentary format.

- collection.tsv
  - Dataset used by the ColBERT-based approach.

- requirements.txt / libraries_list.txt
  - Python dependencies for the project.

# Setup & Installation

Create and activate a virtual environment (recommended):
```

bash python -m venv venv source venv/bin/activate # Linux/Mac
or
venv\Scripts\activate # Windows``` 

Install the required libraries:
```

bash pip install --upgrade pip pip install -r requirements.txt``` 

Set up ColBERT (optional, for the advanced IR approach). If needed:
```

bash pip install git+https://github.com/stanford-futuredata/ColBERT.git@<commit_hash>
``` 

Also place or unzip the pretrained model (e.g., colbertv2.0) in the specified location.

# Usage Guide

- Building an Inverted Index
  - Ensure your document directory is set (e.g., Collection/docs).
  - Run script1.py to build and save the index.

- Running TF-IDF and Querying
  - Quick demo with raw TF-IDF:
    ```bash
    python rawscript2.py
    ```
    This loads the inverted index, computes TF-IDF, answers a sample query, and writes top results to query_results.txt.
  - For logarithmic TF variants, use logscript2.py or main.py.

- Comparing with scikit-learn
  - Cross-check with:
    ```
    bash
    python script2skcheck.py
    ```

- ColBERT Indexing and Searching (optional)
  - Index:
    ```
    bash
    python script3.py
    ```
  - Search:
    ```
    bash
    python script32.py
    ```
    Results are saved to colbert_index.ranking.tsv.

- Evaluation
  - After producing query_results.txt (TF-IDF) and colbert_index.ranking.tsv (ColBERT), run:
    ```
    bash
    python script4.py
    ```
  - Computes precision and recall against known relevant docs.

# Tips and Best Practices

- Verify document paths (e.g., documents_directory) before running.
- Keep index/data paths consistent across scripts.
- For fair comparisons, ensure both systems use the same corpus and preprocessing.
- For large corpora, consider chunking and monitoring memory usage.

# Conclusion

This project showcases:
- Basic text preprocessing (NLTK)
- Building an inverted index
- Querying with TF-IDF (raw and logarithmic variants)
- Advanced IR with ColBERT
- Evaluating with precision and recall

It’s intended as a practical, swappable set of scripts to learn, compare, and extend IR methods.
```
