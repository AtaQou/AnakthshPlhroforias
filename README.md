Overview
This project demonstrates various approaches to Information Retrieval (IR) in Python using a collection of medical-text documents. It covers these main topics:
Building an Inverted Index from text.
Using TF-IDF ranking to answer queries (multiple variants: raw TF, logarithmic TF, etc.).
Comparing TF-IDF ranking with more advanced methods (ColBERT).
Evaluating results using metrics such as Precision and Recall.
Although the project references medical texts, it is a general demonstration of IR techniques, with specific focus on:
• Preprocessing text (including tokenization, stemming, and stopword removal)
• Building, storing, and reading inverted indexes
• Computing TF-IDF scores in different ways (raw and logarithmic)
• Performing queries and ranking documents by cosine similarity
• Evaluating your indexing and search engine results versus a more advanced pretrained model (ColBERT)
 
Project Structure
Below are some of the key files and their purposes (these are the most relevant for getting started). The code is split up to demonstrate multiple ways of building and querying an IR system:

script1.py
Reads documents from a folder and builds a simple inverted index.
Demonstrates basic text preprocessing.
Saves the inverted index to a file (inverted_index.py).

tfidfscript.py
Extends the baseline approach by computing TF-IDF scores with an optional logarithmic term frequency.
Prints and optionally saves the TF-IDF matrix.
rawscript2.py / rawscript2detailed.py
Variations of scripts that read an inverted index file and apply TF-IDF.
Allow for comparing raw TF vs. logarithmic TF.
Demonstrate how to query the documents, compute scores, and write the top results to an output file.

logscript2.py
Another variation combining logarithmic TF with IDF.
Provides an example query and writes top results to a file.

main.py
Example script that pulls everything together:
Reads an inverted index.
Calculates TF-IDF with simple logarithmic normalization.
Queries for “Is CF mucus abnormal” and records top results.

script2skcheck.py
Demonstrates using scikit-learn’s TfidfVectorizer for cross-checking your TF-IDF results.
Compares manual IR with an out-of-the-box library approach.
script3.py / script32.py
Show how to index and search documents using ColBERT, a more advanced approach to IR.
Assumes you have the ColBERT repo (or installed via the provided Git URL).
script3.py creates an index.
script32.py performs the searching.
script4.py
Reads query results (both your own TF-IDF system and ColBERT’s) and computes Precision@N / Recall@N.
Illustrates how to compare different retrieval methods.
csvtotsv.py / docstocsv.py
Converts raw .docs files into .csv or .tsv for any pipeline that needs them (e.g., for ColBERT, or for scikit-learn ingestion).
inverted_index.py
Generated by script1.py. Holds the terms and document IDs in a rudimentary format.
collection.tsv
Large textual dataset used by the ColBERT-based approach. The truncated snippet of its contents shows medical abstracts used for testing retrieval.
requirements.txt / libraries_list.txt
Provide the Python dependencies needed to run the project. See instructions below on installing them via a virtual environment.
 
Setup & Installation
Create and activate a virtual environment (Recommended)``` bash
   python -m venv venv
   source venv/bin/activate  # On Linux/Mac
   #   or
   venv\Scripts\activate     # On Windows
```

Install the required libraries
Inside the activated virtual environment:``` bash
   pip install --upgrade pip
   pip install -r requirements.txt
```

or refer to libraries_list.txt if you want to see a more explicit list.
Set up ColBERT (Optional, if you plan to use the advanced IR approach)
If you wish to run script3/script32 for ColBERT-based indexing and searching, you need the colbert_ai library:``` bash
   # You normally have this from requirements.txt, but if needed:
   pip install git+https://github.com/stanford-futuredata/ColBERT.git@<commit_hash>
```

Also place or unzip the pretrained model (e.g., colbertv2.0) in the specified location.
 
Usage Guide
Building an Inverted Index
Make sure your document directory is set in the Python script (e.g., Collection/docs).
Run script1.py. It reads all .txt files in Collection/docs, preprocesses them, and saves the index as inverted_index.py.
Running TF-IDF and Querying
For a quick demonstration of raw TF-IDF:``` bash
     python rawscript2.py
```

It will load inverted_index.txt, compute TF-IDF, and answer a sample query. Top results go to query_results.txt.
If you want the other approach with a logarithmic TF variant, you can use logscript2.py or main.py. Each script sets up slightly different TF-IDF methods and writes results to a file.
Comparing with scikit-learn
Run python script2skcheck.py. It uses TfidfVectorizer to do the same process for a quick cross-check.
ColBERT Indexing and Searching
(Optional) Run python script3.py to index your .tsv corpus. (You must have your collection.tsv prepared.)
Run python script32.py to perform the search. The top results, typically up to 100, are saved in colbert_index.ranking.tsv.
Evaluation
After you have your query_results.txt from your TF-IDF code and your colbert_index.ranking.tsv from ColBERT, run python script4.py.
It compares the top documents from both systems against a known set of “relevant” docs and computes precision and recall.
File Converters (csvtotsv.py / docstocsv.py)
These are helper scripts to transform your .docs or .csv files into .tsv (or vice versa). Handy if you need to feed data into specific code that expects certain file formats.
 
Tips and Best Practices
Always verify your document path variables (e.g., documents_directory) before running.
If you add new scripts or more advanced ranking methods, ensure they point to the correct index files and data directories.
If you want to compare results (Precision, Recall, F1, etc.), maintain consistent file paths for both your own IR method’s output and the ColBERT output.
For large document collections, consider adjusting memory usage or chunking text to avoid memory issues.
 
Conclusion
In summary, this project provides a teaching example of:
Basic text preprocessing in Python (NLTK).
Building an inverted index.
Querying documents using TF-IDF and comparing multiple TF-IDF variants.
Running advanced IR with ColBERT and verifying results.
Using precision and recall metrics to evaluate and compare the retrieval systems.